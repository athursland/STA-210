---
title: "Final Project"
author: "Ali Thursland and Mary Helen Wood"
date: "11/20/2018"
output: html_document
---

# Setup

```{r setup, warning=FALSE, echo=FALSE, message=FALSE}
#Setup
library("dplyr")
library("ggplot2")
library("broom")
library("knitr")
library("cowplot")
library("readr")
library("dslabs")
library("varhandle")
library("olsrr")
library("car")
```

If you would like to see our data preparation process, please refer to our additional work. We chose to omit it from this file because of the high amount of preparation this data had to undergo to make it workable. We wanted our file to knit more easily. 

```{r data}
#Read file
airbnb <- read.csv("https://raw.githubusercontent.com/athursland/STA-210/master/finalairbnb.csv")
glimpse(airbnb)
```

# Separate training and testing

```{r separate}
#80% of the sample size
smp_size <- floor(0.80 * nrow(airbnb))

#set the seed to make your partition reproducible
set.seed(123456)
train_ind <- sample(seq_len(nrow(airbnb)), size = smp_size)

train.airbnb <- airbnb[train_ind, ]
test.airbnb <- airbnb[-train_ind, ]
```

# Description of data

*Question of interest:* How can we produce a model that accurately predicts the listed nightly price for an Airbnb in Asheville, NC?

  The data set we are using is a .csv file of every AirBnB listing in the city of Asheville, North Carolina as of October 17, 2018. Each observation is an individual listing. We sourced this data from Inside AirBnB, a website that regularly scrapes data from AirBnB’s listings and provides them as public data sets separated by city.

  The original data set was very large (96 columns and 1,936 observations), so we reduced it for simplicity’s sake. We chose 26 columns that could potentially be of interest for a regression analysis, and we created one more column called has_reviews, which is an indicator variable. We noticed that some columns, like cleaning_fee and security_deposit, had a lot of NAs, so instead of omitting all of these observations we mutated NAs from these columns to be 0s. We were left with 24 incomplete cases, likely the result of web scraping errors, and so we chose to omit them. Our final number of columns was 27 and our final number of rows was 1,900. 

Variables: 
* host_response_rate
* host_is_superhost
* host_listings_count
* zipcode
* property_type
* room_type
* accomodates
* bathrooms
* beds
* bed_type
* price
* security_deposit
* cleaning_fee
* guests_included 
* extra_people_cost
* minimum_nights
* maximum_nights
* availability_30
* number_of_reviews
* review_scores_rating
* review_scores_accuracy
* review_scores_cleanliness
* review_scores_checkin
* review_scores_communication
* review_scores_location
* review_scores_value
* reviews_per_month
* cancellation_policy

# Background

Airbnb, inc. is a privately held global company headquartered in San Francisco that operates as a broker for lodging arrangements. Made famous by celebrities like Kim Kardashian, the company is revolutionizing the way people vacation. Rather than booking a hotel, users can go on the AirBnB website or mobile app and quickly rent private rooms, guest suites or even entire homes to themselves. The company has often faced controversy surrounding housing affordability, pricing transparency, privacy and hotel industry competition. Despite these concerns, it blew by its own internal forecasts and brought in 2.6 billion dollars in revenue and 93 million in profit by the end of 2017. For a company that exclusively makes money by taking a small commission (3%) of the price of every listing, that’s pretty impressive.
  
  We were interested in this data because it’s something that so many people, especially our peers here at Duke, would find relevant. There are over 4 million AirBnB listings worldwide and 150 million global users. Both Mary Helen and I have stayed in an AirBnB in the last month. With the option to rent entire homes, AirBnBs offer more luxury, space and solitude than other lodging options. Hosts set prices for listings at their own discretion, and so there isn’t any specific algorithm or model by which it’s calculated. By using this data to create a model that can accurately predict prices for listings, we might be able to help people figure out what the typical price range is for the type of listing they want – and therefore, whether or not a specific listing is a good deal. Specifically, we’ll be looking at AirBnB listings in the Asheville Metro Area, North Carolina. Asheville is a popular weekend getaway in North Carolina. Given its relative proximity to Duke, many students visit at least once during their time here – often staying in AirBnBs when they do. This makes our data more relevant to our peers, and also helps us by narrowing down the total number of observations into a size that’s more manageable.

# Exploratory Data Analysis

```{r pairs-plots with log transformations}
#Pairs plots for all of the explanatory variables
pairs(logprice ~ cancellation_policy + host_is_superhost + host_listings_count, data=train.airbnb)
pairs(logprice ~ zipcode + beds + bathrooms, data=train.airbnb)
pairs(logprice ~ accommodates + room_type + bed_type, data=train.airbnb)
pairs(logprice ~ security_deposit + cleaning_fee + guests_included, data = train.airbnb)
pairs(logprice ~ extra_people + log(minimum_nights) + availability_30, data = train.airbnb)
pairs(logprice ~ log(number_of_reviews +1) + log(review_scores_rating +1) + review_scores_accuracy, data = train.airbnb)
pairs(logprice ~ log(review_scores_cleanliness +1) + review_scores_checkin + review_scores_communication, data = train.airbnb)
pairs(logprice ~ log(review_scores_location +1) + review_scores_value + log(reviews_per_month +1), data = train.airbnb)
pairs(logprice ~ inzip28801 + inzip28804, data = train.airbnb)
```

```{r price-boxplot, warning=FALSE}
#Distribution of price
ggplot(train.airbnb, aes(x=price)) + geom_histogram(fill="#FF5A5F") + geom_vline(aes(xintercept=mean(price)),
            color="#006cb7", linetype="dashed", size=1) +
  labs(title="Distribution of price") + 
  theme(plot.title=element_text(colour="#006cb7", family="Helvetica", face="bold", size=20),
        axis.title=element_text(colour="#006cb7", family="Helvetica"))

#Distribution of logprice
ggplot(train.airbnb, aes(x=logprice)) + geom_histogram(fill="#FF5A5F") + geom_vline(aes(xintercept=mean(logprice)),
            color="#006cb7", linetype="dashed", size=1) + labs(title="Distribution of logprice") +
  theme(plot.title=element_text(colour="#006cb7", family="Helvetica", face="bold", size=20),
        axis.title=element_text(colour="#006cb7", family="Helvetica"))

#Boxplot of price by bed type
ggplot(train.airbnb, aes(x=bed_type, y=logprice)) + geom_boxplot() + labs(title="Distribution of log nightly price by bed type")

#Boxplot of price by room type
ggplot(train.airbnb, aes(x=room_type, y=logprice)) + geom_boxplot() + labs(title="Distribution of log nightly price by room type")

#Distribution of Cleaning Fees
ggplot(train.airbnb, aes(x=cleaning_fee)) + geom_histogram() + labs(title="Distribution of cleaning fees")

#Boxplot of log price by bed type
ggplot(train.airbnb, aes(x=bed_type, y=logprice)) + geom_boxplot()
```

# Model building

*NOTE* -> we are omitting host_response_rate from our model because we were having trouble converting the variable to a numeric without losing a lot of the information. Will address before final due date.

```{r full-model}
#full model
full.model <- lm(logprice ~ host_is_superhost
+ host_listings_count
+ zipcode
+ room_type
+ accommodates
+ bathrooms
+ beds
+ bed_type
+ cleaning_fee
+ extra_people
+ minimum_nights
+ availability_30
+ log.number_of_reviews
+ log.review_scores_rating
+ log.review_scores_accuracy
+ log.review_scores_cleanliness
+ log.review_scores_checkin
+ log.review_scores_communication
+ log.review_scores_location
+ log.review_scores_value
+ log.reviews_per_month
+ cancellation_policy, data=train.airbnb)

tidy(full.model)
```

```{r interactions}
#model with interaction effects
interactions.model <- lm(logprice ~ cleaning_fee * bathrooms + cleaning_fee * accommodates + room_type * bathrooms + accommodates * bathrooms + cleaning_fee * log.review_scores_cleanliness + availability_30 * minimum_nights + cancellation_policy * accommodates + host_is_superhost
+ host_listings_count
+ room_type
+ accommodates
+ bathrooms
+ beds
+ bed_type
+ cleaning_fee
+ extra_people
+ minimum_nights
+ availability_30
+ log.number_of_reviews
+ log.review_scores_rating
+ log.review_scores_accuracy
+ log.review_scores_cleanliness
+ log.review_scores_checkin
+ log.review_scores_communication
+ log.review_scores_location
+ log.review_scores_value
+ log.reviews_per_month
+ cancellation_policy, data=train.airbnb)

#anova test
#kable(anova(full.model, interactions.model)) # there is a significant interaction term
```

```{r stepwise-interactions, warning=FALSE}
stepwise.interactions.model <- ols_step_both_aic(interactions.model, details=FALSE)
```

```{r final-model}
#final model after self selection
final.model <- lm(logprice ~ cleaning_fee * accommodates + availability_30 * minimum_nights
+ host_is_superhost
+ room_type
+ accommodates
+ cleaning_fee
+ minimum_nights
+ availability_30
+ log.reviews_per_month
+ cancellation_policy, data=train.airbnb)

kable(tidy(final.model), format="markdown", digits = 4)
```

```{r, examine zip code, warning=FALSE}
table2 <- airbnb %>% group_by(zipcode) %>% summarise(n=n())
kable(table2)

#zip code has high p values for areas with large observation counts and small alike. Only two zip codes are significant - make indicator variable to reduce noise. 
# also: extra people is high so I vote we self select it out
```

# Prediction

<<<<<<< HEAD
```{r testing-model}
#Applying our model to the testing set
test.model <- lm(logprice ~ cleaning_fee * accommodates + availability_30 * minimum_nights
+ host_is_superhost
+ room_type
+ accommodates
+ cleaning_fee
+ minimum_nights
+ availability_30
+ log.reviews_per_month
+ cancellation_policy, data=test.airbnb)
=======
#```{r predict-testing, warning=FALSE}
#Predict on the testing set using our final model
test.airbnb <- test.airbnb %>% mutate(predict = predict.lm(stepwise.interactions.model, test.airbnb))
>>>>>>> 2f393114826db2904ad6a65427913d1377a5aa9f

tidy(test.model)
tidy(final.model)
```

```{r predict-training, warning=FALSE}
#Predict on the training set using our final model
train.airbnb <- train.airbnb %>% mutate(predict = predict.lm(final.model, train.airbnb))

#Raw resids for training set
train.airbnb <- train.airbnb %>% mutate(raw.resid = logprice - predict)
```

```{r predict-testing}
#Predict on the testing set using our final model
test.airbnb <- test.airbnb %>% mutate(predict = predict.lm(final.model, test.airbnb))

#Raw resids for testing set
test.airbnb <- test.airbnb %>% mutate(raw.resid = logprice - predict)

#Residuals vs. Predicted
ggplot(test.airbnb, aes(x=predict, y=raw.resid)) + geom_point(colour="#006cb7") + 
  labs(title = "Residuals vs Predicted", subtitle = "Test Data Set", x = "predicted", y = "residual") +
  geom_hline(yintercept=0,color="#FF5A5F") + 
  theme(plot.title=element_text(colour="#FF5A5F", family="Helvetica", face="bold", size=20),
        axis.title=element_text(colour="#FF5A5F", family="Helvetica"),
        plot.subtitle=element_text(hjust=0.5, colour="#FF5A5F", family="Helvetica"))

#Calculate MSE
mse.train <- mean(train.airbnb$raw.resid^2)
mse.test  <- mean(test.airbnb$raw.resid^2)
mse.diff <- mse.test - mse.train

#Print MSE + difference
print(mse.train)
print(mse.test)
<<<<<<< HEAD
print(mse.diff)
```
=======
```

```{r select}
sample <- sample_n(test.airbnb, 2)
sample
```

## Example Prediction
```{r, observation 43}
x0 = data.frame(host_is_superhost= "t", room_type = "Entire home/apt", accommodates = 5, logprice = log(95), cleaning_fee = 75, minimum_nights = 1, availability_30 = 4, number_of_reviews = 95, log.reviews_per_month = log(1.42), cancellation_policy = "moderate")


#random variables
x1 = data.frame(host_is_superhost= "t", room_type = "Entire home/apt", accommodates = 4, cleaning_fee = 10, minimum_nights = 1, availability_30 = 15, number_of_reviews = 100, log.reviews_per_month = log(1.5), cancellation_policy = "strict_14_with_grace_period")

predict.lm(stepwise.interactions.model,x0,interval="prediction")

exp(5.140246)
exp(4.353211)
exp(5.92728)

```


>>>>>>> 2f393114826db2904ad6a65427913d1377a5aa9f
